{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1: KMEANS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./kMeansData.csv\")\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please remember to normalize the data as preprocessing\n",
    "scalar = MinMaxScaler()\n",
    "data = scalar.fit_transform(data)\n",
    "data = pd.DataFrame(data, columns=['x1','x2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot before implement kmeans algorithm\n",
    "plt.plot(data.x1, data.x2, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "demonstration step-by-step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: Randomly pick centroids\n",
    "random.seed(123)\n",
    "centroids = np.c_[\n",
    "    [random.uniform(min(data.x1), max(data.x1)) for i in range(3)],\n",
    "    [random.uniform(min(data.x2), max(data.x2)) for i in range(3)]\n",
    "]\n",
    "# 3*2 matrix: 3 centroid, 2 dimenstions for each (x1, x2)\n",
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix\n",
    "# step 2: Distance from points to centroids\n",
    "dist = distance_matrix(data, centroids)\n",
    "# dist is a 150 * 3 distance matrix, \n",
    "# 150 rows represents 150 trainting points, 3 columns means the distance to 3 centroids\n",
    "\n",
    "# 150 * 3 explaination: \n",
    "# for example #3 row, #0 col means the distance between the 4th training point and the 1st centroid\n",
    "dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the training with nearest centroid's label\n",
    "labels = dist.argmin(axis=1)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update centroids\n",
    "old_centroids, centroids = centroids, np.array([\n",
    "    data.iloc[np.where(labels==0)[0],0:2].mean(),\n",
    "    data.iloc[np.where(labels==1)[0],0:2].mean(), \n",
    "    data.iloc[np.where(labels==2)[0],0:2].mean()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the error: culmulate 3 new centroids' \"moving\" distance\n",
    "tolerance = 0\n",
    "for k in range(3):\n",
    "    tolerance += np.linalg.norm(old_centroids[k]- centroids[k])\n",
    "    \n",
    "tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the above step:\n",
    "def calculate_cluster(X, centroids):\n",
    "    dist = distance_matrix(X,centroids)\n",
    "    return dist.argmin(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_centroid(X, labels, centroids):\n",
    "\n",
    "    old_centroids, centroids = centroids, np.array([\n",
    "        data.iloc[np.where(labels==0)[0],0:2].mean(),\n",
    "        data.iloc[np.where(labels==1)[0],0:2].mean(), \n",
    "        data.iloc[np.where(labels==2)[0],0:2].mean()\n",
    "    ])\n",
    "    tolerance = 0\n",
    "    for k in range(3):\n",
    "        tolerance += np.linalg.norm(old_centroids[k]- centroids[k])\n",
    "    return centroids, tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# begin to train:\n",
    "random.seed(456)\n",
    "centroids = np.c_[\n",
    "    [random.uniform(min(data.x1), max(data.x1)) for i in range(3)],\n",
    "    [random.uniform(min(data.x2), max(data.x2)) for i in range(3)]\n",
    "]\n",
    "\n",
    "for epoch in range(1000):\n",
    "    labels = calculate_cluster(data, centroids)\n",
    "    centroids, tolerance = calculate_centroid(data, labels, centroids)\n",
    "    # I decide to set the early stop point as 0.0001 for a higher precision\n",
    "    if tolerance < 0.0001:\n",
    "        print(epoch, tolerance)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the trained cluster_centroids and cluster label\n",
    "centroids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "plt.plot(data.iloc[np.where(labels==0)[0],0], data.iloc[np.where(labels==0)[0],1], 'o', alpha=0.4)\n",
    "plt.plot(data.iloc[np.where(labels==1)[0],0], data.iloc[np.where(labels==1)[0],1], 'o', alpha=0.4)\n",
    "plt.plot(data.iloc[np.where(labels==2)[0],0], data.iloc[np.where(labels==2)[0],1], 'o', alpha=0.4)\n",
    "\n",
    "plt.plot(centroids[:,0], centroids[:,1], 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "confirmation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(data)\n",
    "print(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], 'ro')\n",
    "plt.plot(data[kmeans.labels_ == 0]['x1'], data[kmeans.labels_ == 0]['x2'], 'o', alpha=0.4)\n",
    "plt.plot(data[kmeans.labels_ == 1]['x1'], data[kmeans.labels_ == 1]['x2'], 'o', alpha=0.4)\n",
    "plt.plot(data[kmeans.labels_ == 2]['x1'], data[kmeans.labels_ == 2]['x2'], 'o', alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2: RBF Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf = pd.read_csv('./rbfClassification.csv')\n",
    "# Normalization\n",
    "scalar = MinMaxScaler()\n",
    "rbfnorm = scalar.fit_transform(rbf[['x1','x2']])\n",
    "rbfnorm = pd.DataFrame(np.c_[rbfnorm, rbf.cls], columns=['x1','x2', 'cls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(rbfnorm[['x1', 'x2']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report cluster centers coordinate\n",
    "centroids = kmeans.cluster_centers_\n",
    "centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix\n",
    "r = distance_matrix(rbfnorm[['x1', 'x2']], centroids)\n",
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the hyper-parameters\n",
    "ngamma = -0.5\n",
    "phi = np.exp(ngamma*r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the phi\n",
    "phi = np.c_[[1]*20, phi]\n",
    "phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the parameters\n",
    "w = np.dot( np.linalg.pinv(phi), rbfnorm.cls )\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the probability\n",
    "pred_prob = phi @ w.reshape(-1,1)\n",
    "pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the threshold\n",
    "pred = list(map(lambda x: 1 if x>=0.5 else 0, pred_prob))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "sum(pred == rbfnorm.cls) / 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compared with the kmeans without kernel:\n",
    "sum(kmeans.predict(rbfnorm[['x1','x2']]) == rbfnorm.cls) / 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
