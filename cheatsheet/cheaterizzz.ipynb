{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias and variance\n",
    "### This is when our data is a real world csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant model - Bias squared: 0.4469833029447595, Variance: 1.7749370367472766e-30, Total error: 0.4469833029447595\n",
      "Linear model - Bias squared: 0.43462887519290133, Variance: 0.6592638888888882, Total error: 1.0938927640817895\n",
      "Regularized model - Bias squared: 0.43462889006674554, Variance: 0.6586827550924926, Total error: 1.0933116451592382\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "def f(X):\n",
    "    # Define the true function\n",
    "    return np.mean(X, axis=1)\n",
    "\n",
    "def calculate_bias_variance(model, X_train, y_train, X_test, y_test):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Calculate the average prediction\n",
    "    average_prediction = np.mean(model.predict(X_test))\n",
    "\n",
    "    # Calculate the bias\n",
    "    bias = np.mean((average_prediction - y_test)**2)\n",
    "\n",
    "    # Calculate the variance\n",
    "    variance = np.mean(np.var(model.predict(X_test), axis=0))\n",
    "\n",
    "    return bias, variance\n",
    "\n",
    "def main():\n",
    "    # Load the Iris dataset\n",
    "    iris = load_iris()\n",
    "    X = iris.data\n",
    "    y = f(X)  # Apply the true function\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create a constant model\n",
    "    constant_model = DummyRegressor(strategy='mean')\n",
    "    constant_bias, constant_variance = calculate_bias_variance(constant_model, X_train, y_train, X_test, y_test)\n",
    "    constant_error = constant_bias**2 + constant_variance\n",
    "\n",
    "    # Create a linear model\n",
    "    linear_model = LinearRegression()\n",
    "    linear_bias, linear_variance = calculate_bias_variance(linear_model, X_train, y_train, X_test, y_test)\n",
    "    linear_error = linear_bias**2 + linear_variance\n",
    "\n",
    "    # Create a regularized model\n",
    "    lambda_reg = 0.1\n",
    "    regularized_model = Ridge(alpha=lambda_reg)\n",
    "    regularized_bias, regularized_variance = calculate_bias_variance(regularized_model, X_train, y_train, X_test, y_test)\n",
    "    regularized_error = regularized_bias**2 + regularized_variance\n",
    "\n",
    "\n",
    "    print(f\"Constant model - Bias squared: {constant_bias**2}, Variance: {constant_variance}, Total error: {constant_error}\")\n",
    "    print(f\"Linear model - Bias squared: {linear_bias**2}, Variance: {linear_variance}, Total error: {linear_error}\")\n",
    "    print(f\"Regularized model - Bias squared: {regularized_bias**2}, Variance: {regularized_variance}, Total error: {regularized_error}\")\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias, Variance & Regularization\n",
    "### This is when our data is in the form of coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For constant model, avg g(x)= -0.002 \n",
      "For linear model, avg g(x)= 0.786 x+ -0.001 \n",
      "For linear model with regularization, avg g(x)= 0.627 x+ -0.001\n",
      "---------------------------------------------\n",
      "Bias Sq for constant model is: 0.497\n",
      "Variance for constant model is: 0.247\n",
      "---------------------------------------------\n",
      "Bias sq for unreg linear model is: 0.204\n",
      "Variance for unreg linear model is: 1.66\n",
      "---------------------------------------------\n",
      "Bias sq for regularized linear model is: 0.23\n",
      "Variance for unreg linear model is: 0.329\n",
      "---------------------------------------------\n",
      "Total error for constant model is: 0.744\n",
      "Total error for unreg linear model is: 1.864\n",
      "Total error for regularized linear model is: 0.559\n"
     ]
    }
   ],
   "source": [
    "# Loading the data\n",
    "# Remember to change the data as per the question\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame({'x1':np.random.uniform(-1, 1, size=(10_000)),\\\n",
    "                    'x2': np.random.uniform(-1, 1, size=(10_000)),})\n",
    "\n",
    "# True function f(x)\n",
    "def f(x):\n",
    "    return np.sin(np.pi*x)\n",
    "\n",
    "df['y1'] = f(df['x1'])\n",
    "df['y2'] = f(df['x2'])\n",
    "\n",
    "'''Constant hypothesis'''\n",
    "df['g_cons'] = df[['y1','y2']].mean(axis=1)\n",
    "\n",
    "def findEqLine(x1, x2, y1, y2):\n",
    "    '''\n",
    "    This function takes 2 scalers for x1, and x2, and 2 scalers for y1, and y2.\n",
    "    It will find the equation of a line that passes through these 2 points using matrix inverse.\n",
    "    This function outputs the intercept and slope of the line (i.e intercept = w[0], slope = w[1])\n",
    "    '''\n",
    "    X = np.array([[1, x1], [1, x2]])\n",
    "    lamb = 0.1\n",
    "    I=np.identity(2)\n",
    "    w = np.linalg.pinv(X.transpose()@X)@X.transpose()@np.array([y1,y2])\n",
    "    w_reg = np.linalg.pinv(X.transpose()@X+lamb*I)@X.transpose()@np.array([y1,y2])\n",
    "    return(w, w_reg)\n",
    "\n",
    "# Run the above function for all 10,000 points. This will give us 10,000 slopes and intercepts.\n",
    "for i in range(df.shape[0]):\n",
    "    df.loc[i,'g_line_b'] = findEqLine(df.loc[i,'x1'], df.loc[i,'x2'], df.loc[i,'y1'], df.loc[i,'y2'])[:][0][0]\n",
    "    df.loc[i,'g_line_m'] = findEqLine(df.loc[i,'x1'], df.loc[i,'x2'], df.loc[i,'y1'], df.loc[i,'y2'])[:][0][1]\n",
    "    df.loc[i,'g_line_b_reg'] = findEqLine(df.loc[i,'x1'], df.loc[i,'x2'], df.loc[i,'y1'], df.loc[i,'y2'])[:][1][0]\n",
    "    df.loc[i,'g_line_m_reg'] = findEqLine(df.loc[i,'x1'], df.loc[i,'x2'], df.loc[i,'y1'], df.loc[i,'y2'])[:][1][1]\n",
    "\n",
    "'''Aveerage hypothesis for each model'''\n",
    "\n",
    "g_cons_bar = df['g_cons'].mean()\n",
    "g_line_m_bar = df['g_line_m'].mean()\n",
    "g_line_b_bar = df['g_line_b'].mean()\n",
    "g_line_m_reg_bar = df['g_line_m_reg'].mean()\n",
    "g_line_b_reg_bar = df['g_line_b_reg'].mean()\n",
    "print('For constant model, avg g(x)=', np.round(g_cons_bar,3),\\\n",
    "      '\\nFor linear model, avg g(x)=', np.round(g_line_m_bar,3),\\\n",
    "      'x+',np.round(g_line_b_bar,3),\\\n",
    "      '\\nFor linear model with regularization, avg g(x)=', np.round(g_line_m_reg_bar,3),\\\n",
    "      'x+',np.round(g_line_b_reg_bar,3)\n",
    "     )\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "'''Constant model'''\n",
    "# bias^2 at x = (g_bar(x) - f(x))^2\n",
    "# For constant model g_bar is the same at all x's\n",
    "bias_cons_atX = (df['y1']-g_cons_bar)**2\n",
    "#To find bias^2 we need to find E[bias^2 at x]. => Take expected value horizontally\n",
    "bias_cons = np.mean(bias_cons_atX)\n",
    "print('Bias Sq for constant model is:', np.round(bias_cons,3))\n",
    "\n",
    "var_cons = np.mean((df['g_cons']-g_cons_bar)**2)\n",
    "print('Variance for constant model is:', np.round(var_cons,3))\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "'''Unreg Linear model'''\n",
    "df['g_line_bar_atX'] = g_line_b_bar + g_line_m_bar*df['x1']\n",
    "#Alternatively can use np.matmul(np.array([g_line_b_bar,g_line_m_bar]),np.array([np.ones(10000), df['x']]))\n",
    "bias_linear_atX = (df['y1']-df['g_line_bar_atX'])**2\n",
    "bias_linear = np.mean(bias_linear_atX)\n",
    "print('Bias sq for unreg linear model is:', np.round(bias_linear,3))\n",
    "\n",
    "g_linear_x = pd.DataFrame(np.matmul(np.array(df[['g_line_b','g_line_m']]),np.array([np.ones(10000), df['x1'] ])))\n",
    "# To find g(x)-g_bar(x), every columns of g_linear_x must be subtracted from g_bar(x)\n",
    "temp = g_linear_x.sub(df['g_line_bar_atX'], axis = 'columns')**2\n",
    "varAt_x = temp.mean()\n",
    "var_line = np.mean(varAt_x)\n",
    "print('Variance for unreg linear model is:', np.round(var_line,3))\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "'''Reg Linear model'''\n",
    "# Unlike constant model we have to evalute g_bar at every x\n",
    "df['g_line_bar_reg_atX'] = g_line_b_reg_bar + g_line_m_reg_bar*df['x1']\n",
    "#Alternatively can use np.matmul(np.array([g_line_b)reg_bar,g_line_m_reg_bar]),np.array([np.ones(10000), df['x']]))\n",
    "bias_linear_reg_atX = (df['y1']-df['g_line_bar_reg_atX'])**2\n",
    "bias_linear_reg = np.mean(bias_linear_reg_atX)\n",
    "print('Bias sq for regularized linear model is:', np.round(bias_linear_reg,3))\n",
    "\n",
    "g_linear_reg_x = pd.DataFrame(np.matmul(np.array(df[['g_line_b_reg','g_line_m_reg']]),np.array([np.ones(10000), df['x1'] ])))\n",
    "# To find g(x)-g_bar(x), every columns of g_linear_x must be subtracted from g_bar(x)\n",
    "temp = g_linear_reg_x.sub(df['g_line_bar_reg_atX'], axis = 'columns')**2\n",
    "varAt_reg_x = temp.mean()\n",
    "var_line_reg = np.mean(varAt_reg_x)\n",
    "print('Variance for unreg linear model is:', np.round(var_line_reg,3))\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "print(\"Total error for constant model is:\", np.round(bias_cons+var_cons,3))\n",
    "print(\"Total error for unreg linear model is:\", np.round(bias_linear+var_line,3))\n",
    "print(\"Total error for regularized linear model is:\", np.round(bias_linear_reg+var_line_reg,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [1. 1. 0.]\n",
      "Mean accuracy: 0.6666666666666666\n",
      "Cross-validation scores: [1.         1.         0.93333333 0.96666667 0.96666667]\n",
      "Mean accuracy: 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "# using kfold with custom data:\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Sample data\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "y = np.array([0, 0, 1, 1])\n",
    "\n",
    "# Create a logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Define the number of splits for k-fold cross-validation\n",
    "n_splits = 3\n",
    "\n",
    "# Initialize the k-fold cross-validation\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "cv_scores = cross_val_score(model, X, y, cv=kf)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "\n",
    "# Calculate and print the mean accuracy\n",
    "print(\"Mean accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# using kfold with iris data:\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Create a logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Define the number of splits for k-fold cross-validation\n",
    "n_splits = 5\n",
    "\n",
    "# Initialize the k-fold cross-validation\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "cv_scores = cross_val_score(model, X, y, cv=kf)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "\n",
    "# Calculate and print the mean accuracy\n",
    "print(\"Mean accuracy:\", cv_scores.mean())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# using kfold with a dataset:\n",
    "\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# # Load the data from the CSV file\n",
    "# data = pd.read_csv(\"example.csv\")\n",
    "\n",
    "# # Assuming the target column is named 'target', if not replace it with your target column name\n",
    "# X = data.drop('target', axis=1)\n",
    "# y = data['target']\n",
    "\n",
    "# # Create a logistic regression model\n",
    "# model = LogisticRegression()\n",
    "\n",
    "# # Define the number of splits for k-fold cross-validation\n",
    "# n_splits = 5\n",
    "\n",
    "# # Initialize the k-fold cross-validation\n",
    "# kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# # Perform k-fold cross-validation\n",
    "# cv_scores = cross_val_score(model, X, y, cv=kf)\n",
    "\n",
    "# # Print the cross-validation scores\n",
    "# print(\"Cross-validation scores:\", cv_scores)\n",
    "\n",
    "# # Calculate and print the mean accuracy\n",
    "# print(\"Mean accuracy:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13 entries, 0 to 12\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Temperature    13 non-null     object\n",
      " 1   Wind           13 non-null     object\n",
      " 2   Precipitation  13 non-null     object\n",
      " 3   Humidity       13 non-null     object\n",
      " 4   Play           13 non-null     object\n",
      "dtypes: object(5)\n",
      "memory usage: 652.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hot</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Rain</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mild</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mild</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cold</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cold</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Dry</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hot</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Dry</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mild</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>High</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mild</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Rain</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hot</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Dry</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hot</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Rain</td>\n",
       "      <td>Normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cold</td>\n",
       "      <td>Strong</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mild</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Rain</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mild</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Dry</td>\n",
       "      <td>Normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature    Wind Precipitation Humidity Play\n",
       "0          Hot  Strong          Rain     High   No\n",
       "1         Mild    Weak          Rain   Normal  Yes\n",
       "2         Mild    Weak      Overcast   Normal  Yes\n",
       "3         Cold  Strong      Overcast   Normal  Yes\n",
       "4         Cold    Weak           Dry   Normal  Yes\n",
       "5          Hot  Strong           Dry     High   No\n",
       "6         Mild    Weak      Overcast     High  Yes\n",
       "7         Mild  Strong          Rain     High   No\n",
       "8          Hot    Weak           Dry   Normal  Yes\n",
       "9          Hot    Weak          Rain   Normal   No\n",
       "10        Cold  Strong      Overcast     High   No\n",
       "11        Mild    Weak          Rain     High   No\n",
       "12        Mild    Weak           Dry   Normal   No"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('soccerData2.csv')\n",
    "df.info(verbose = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mild</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Rain</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Temperature  Wind Precipitation Humidity\n",
       "0        Mild  Weak          Rain     High"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train = df.iloc[:-2,:] # all rows except the last two\n",
    "# test = df.iloc[-2:,:] # last two rows\n",
    "# select train and test as per the question\n",
    "\n",
    "train = df\n",
    "# Sample question as test point\n",
    "test = pd.DataFrame({'Temperature':'Mild', 'Wind':'Weak', 'Precipitation':'Rain', 'Humidity':'High'}, index=[0])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: ['No']\n",
      "Predicted probability: [[0.78896302 0.21103698]]\n"
     ]
    }
   ],
   "source": [
    "# Using naive bayes to calculate the probability of each class\n",
    "# Create a pipeline\n",
    "categorical_features = ['Temperature', 'Wind', 'Precipitation', 'Humidity']\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', MultinomialNB())])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(train[categorical_features], train['Play'])\n",
    "\n",
    "# Predict the class for the test point\n",
    "predicted_class = model.predict(test)\n",
    "print(\"Predicted class:\", predicted_class)\n",
    "\n",
    "# Calculate the probability of each class for the test point\n",
    "predicted_prob = model.predict_proba(test)\n",
    "print(\"Predicted probability:\", predicted_prob)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
